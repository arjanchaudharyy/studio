import { z } from 'zod';
import {
  componentRegistry,
  ComponentRetryPolicy,
  runComponentWithRunner,
  defineComponent,
  inputs,
  outputs,
  parameters,
  port,
  param,
} from '@shipsec/component-sdk';
import { LLMProviderSchema, llmProviderContractName } from '@shipsec/contracts';
import { IsolatedContainerVolume } from '../../utils/isolated-volume';
import { DEFAULT_GATEWAY_URL, getGatewaySessionToken } from './utils';

const inputSchema = inputs({
  task: port(
    z.string().min(1, 'Task cannot be empty').describe('The investigation task to perform.'),
    {
      label: 'Task',
      description: 'The main objective for the OpenCode agent (e.g. "Investigate these alerts").',
    },
  ),
  context: port(
    z.unknown().optional().describe('Contextual data (JSON) to assist the investigation.'),
    {
      label: 'Context',
      description: 'Optional JSON data providing context (alerts, logs, previous findings).',
      connectionType: { kind: 'primitive', name: 'json' },
      allowAny: true,
      reason: 'Context is a dynamic JSON object.',
    },
  ),
  model: port(
    LLMProviderSchema()
      .default({
        provider: 'openai',
        modelId: 'gpt-4o',
      })
      .describe('Model configuration for the agent.'),
    {
      label: 'Model',
      description: 'LLM provider configuration.',
      connectionType: { kind: 'contract', name: llmProviderContractName, credential: true },
    },
  ),
  tools: port(z.unknown().optional().describe('Anchor for tool-mode nodes.'), {
    label: 'Connected Tools',
    description: 'Connect tool-mode nodes here to expose them to the agent.',
    allowAny: true,
    reason: 'Tool-mode port acts as a graph anchor; payloads are not consumed directly.',
    connectionType: { kind: 'contract', name: 'mcp.tool' },
  }),
});

const parameterSchema = parameters({
  systemPrompt: param(
    z.string().default('').describe('Optional investigator prompt template override.'),
    {
      label: 'System Prompt',
      editor: 'textarea',
      rows: 5,
      description: 'Override the default investigator prompt template.',
    },
  ),
  autoApprove: param(z.boolean().default(true).describe('Automatically approve agent actions.'), {
    label: 'Auto Approve',
    editor: 'boolean',
    description: 'If true, the agent runs without user intervention.',
  }),
  providerConfig: param(
    z
      .record(z.string(), z.unknown())
      .default({})
      .describe('Additional OpenCode provider configuration.'),
    {
      label: 'Provider Config',
      editor: 'json',
      description: 'Additional configuration merged into opencode.jsonc.',
    },
  ),
});

const outputSchema = outputs({
  report: port(z.string(), {
    label: 'Report',
    description: 'The final markdown report generated by the agent.',
  }),
  rawOutput: port(z.string(), {
    label: 'Raw Output',
    description: 'Full stdout/stderr logs from the agent execution.',
  }),
});

const definition = defineComponent({
  id: 'core.ai.opencode',
  label: 'OpenCode Agent',
  category: 'ai',
  runner: {
    kind: 'docker',
    image: 'ghcr.io/anomalyco/opencode',
    entrypoint: 'opencode', // We will override this in execution
    network: 'host' as const, // Required to access localhost gateway
    command: ['help'],
  },
  inputs: inputSchema,
  outputs: outputSchema,
  parameters: parameterSchema,
  docs: 'Runs the OpenCode agent to perform autonomous investigations using connected tools.',
  retryPolicy: {
    maxAttempts: 1, // Agents are expensive/impotent, normally don't retry automatically
    initialIntervalSeconds: 2,
    maximumIntervalSeconds: 10,
    backoffCoefficient: 2,
    nonRetryableErrorTypes: ['ValidationError', 'ConfigurationError'],
  } satisfies ComponentRetryPolicy,
  ui: {
    slug: 'opencode-agent',
    version: '1.0.0',
    type: 'process',
    category: 'ai',
    description: 'Autonomous coding and investigation agent.',
    icon: 'Bot',
    author: {
      name: 'ShipSecAI',
      type: 'shipsecai',
    },
  },
  async execute({ inputs, params }, context) {
    const { task, context: taskContext, model } = inputs;
    const { systemPrompt, providerConfig } = params;

    const { connectedToolNodeIds, organizationId } = context.metadata;

    // 1. Resolve Gateway Token for MCP
    let gatewayToken = '';
    const connectedToolIds = connectedToolNodeIds ?? [];
    if (connectedToolIds.length > 0) {
      try {
        gatewayToken = await getGatewaySessionToken(
          context.runId,
          organizationId ?? null,
          connectedToolIds,
        );
      } catch (error) {
        context.logger.error(`[OpenCode] Failed to generate gateway token: ${error}`);
      }
    }

    // Helper to map provider to OpenCode model string format
    const getOpenCodeModelString = (
      model: { provider: string; modelId: string } | undefined,
    ): string => {
      if (!model) return 'gpt-4o';
      // OpenCode expects models in format: provider/modelId
      // Most providers follow this pattern
      return `${model.provider}/${model.modelId}`;
    };

    // 2. Prepare opencode.json config
    // Note: We use 'host' networking, so we can reach localhost
    // Correct format from https://opencode.ai/docs/mcp-servers/
    // CRITICAL: oauth: false is required for custom headers (OAuth is auto-detected as default in v1.0.137+)
    // See: https://github.com/anomalyco/opencode/issues/5278
    // Always add MCP config (even if token is empty, so OpenCode can attempt connection)
    const mcpConfig = {
      mcp: {
        'shipsec-gateway': {
          type: 'remote' as const,
          url: DEFAULT_GATEWAY_URL,
          oauth: false,
          headers: gatewayToken
            ? {
                Authorization: `Bearer ${gatewayToken}`,
                Accept: 'application/json, text/event-stream',
              }
            : {
                Accept: 'application/json, text/event-stream',
              },
          enabled: true,
        },
      },
    };

    // Build provider config for OpenCode
    // Z.AI requires the API key to be in provider.options.apiKey
    const providerConfigForOpenCode: Record<string, unknown> = {
      ...(model?.provider === 'zai-coding-plan' && model.apiKey
        ? {
            'zai-coding-plan': {
              options: {
                apiKey: model.apiKey,
              },
            },
          }
        : {}),
    };

    const opencodeConfig = {
      ...mcpConfig,
      provider: providerConfigForOpenCode,
      model: getOpenCodeModelString(model),
      permission: 'allow',
      // Merge in any additional provider config from parameters
      ...providerConfig,
    };

    const providerEnv = buildProviderEnv(model);

    // 3. Prepare Context and Prompt
    const contextJson = JSON.stringify(taskContext ?? {}, null, 2);

    // Default investigator prompt if none provided
    const defaultPrompt = `
# Investigation Task
{{TASK}}

# Context
The following context is available in /workspace/context.json.
Please investigate the issue and generate a detailed report.
`;

    // Build final prompt: use systemPrompt if provided, otherwise use default template
    // Always append the task to ensure it's included
    let finalPrompt: string;
    if (systemPrompt?.trim()) {
      finalPrompt = `${systemPrompt}\n\n# Task\n${task}`;
      if (taskContext && Object.keys(taskContext).length > 0) {
        finalPrompt +=
          '\n\n# Context\nThe following context is available in /workspace/context.json.';
      }
    } else {
      finalPrompt = defaultPrompt.replace('{{TASK}}', task);
    }

    // Ask the agent to list available MCP tools first (best-effort).
    finalPrompt =
      `${finalPrompt}\n\n# MCP Tools\n` +
      `Before you start, list the MCP tools you can see. If none are available, say so explicitly.`;

    // 4. Setup Isolated Volume
    const tenantId = (context as any).tenantId ?? 'default-tenant';
    const volume = new IsolatedContainerVolume(tenantId, context.runId);

    try {
      // 5. Execute Docker Container
      // Write a wrapper script to properly execute opencode with file reading
      // The script runs inside the container, so $(cat /workspace/prompt.txt) works correctly
      // Note: --quiet flag doesn't exist in opencode 1.1.34, use --log-level ERROR instead
      const wrapperScript = [
        '#!/bin/sh',
        'set -e',
        'cd /workspace',
        'echo "[OpenCode] Listing MCP tools before run..."',
        'opencode mcp list --log-level ERROR || true',
        'echo "[OpenCode] Starting agent run..."',
        'opencode run --log-level ERROR "$(cat /workspace/prompt.txt)"',
        '',
      ].join('\n');

      const opencodeConfigJson = JSON.stringify(opencodeConfig, null, 2);
      // Initialize workspace with config, context, prompt, and wrapper script
      await volume.initialize({
        'context.json': contextJson,
        // Opencode prefers opencode.jsonc in cwd; keep opencode.json for backwards compat.
        'opencode.jsonc': opencodeConfigJson,
        'opencode.json': opencodeConfigJson,
        'prompt.txt': finalPrompt,
        'run.sh': wrapperScript,
      });

      const runnerConfig = {
        ...definition.runner,
        // Override entrypoint to /bin/sh to avoid the image's default 'opencode' entrypoint
        // The command will be executed as: /bin/sh /workspace/run.sh
        entrypoint: '/bin/sh',
        command: ['/workspace/run.sh'],
        // Use host network to access localhost gateway
        network: 'host' as const,
        env: providerEnv,
        volumes: [
          volume.getVolumeConfig('/workspace', false), // Read-write, mounted at /workspace
        ],
        workingDir: '/workspace',
      };

      // If we are using host network, we might need to handle port collisions or security?
      // For a worker, allow host network is a privileged operation.
      // Assumption: The worker environment allows this / is trusted.

      context.emitProgress({
        message: 'Running OpenCode agent...',
        level: 'info',
      });

      const runnerResult = await runComponentWithRunner(
        runnerConfig,
        async (raw) => raw, // Pass through raw result
        {},
        context,
      );

      // Parse output
      // The runner result handling in runComponentWithRunner usually involves parsing JSON
      // if the entrypoint returns JSON.
      // But here we are using a custom command that prints markdown to stdout.

      // We expect the result to be in the 'raw' or 'stdout' property of the result object
      // depending on how runComponentWithRunner captures it.
      // Based on httpx.ts it seems we get an object with { exitCode, stdout, stderr, raw } or similar
      // if using a standard docker runner adaptor.

      // Let's assume the raw output from the runner wrapper is what we get.
      // In httpx.ts:
      // const httpxRunnerOutputSchema = z.object({
      //   results: z.array(z.unknown()).optional().default([]),
      //   raw: z.string().optional().default(''),
      //   stderr: z.string().optional().default(''),
      //   exitCode: z.number().optional().default(0),
      // });

      // We should inspect what the runner returns.
      // Assuming a generic docker runner returns { stdout, stderr, exitCode }

      let stdout = '';
      let stderr = '';

      if (typeof runnerResult === 'string') {
        stdout = runnerResult;
      } else if (isRecord(runnerResult)) {
        stdout = (runnerResult.stdout as string) || (runnerResult.raw as string) || '';
        stderr = (runnerResult.stderr as string) || '';
      }

      return outputSchema.parse({
        report: stdout, // The markdown report is expected in stdout
        rawOutput: `STDOUT:\n${stdout}\n\nSTDERR:\n${stderr}`,
      });
    } finally {
      await volume.cleanup();
    }
  },
});

function isRecord(value: unknown): value is Record<string, unknown> {
  return typeof value === 'object' && value !== null && !Array.isArray(value);
}

function buildProviderEnv(model?: { provider: string; apiKey?: string }): Record<string, string> {
  if (!model?.apiKey) {
    return {};
  }

  switch (model.provider) {
    case 'openai':
      return { OPENAI_API_KEY: model.apiKey };
    case 'openrouter':
      return { OPENROUTER_API_KEY: model.apiKey };
    case 'anthropic':
      return { ANTHROPIC_API_KEY: model.apiKey };
    case 'groq':
      return { GROQ_API_KEY: model.apiKey };
    case 'xai':
      return { XAI_API_KEY: model.apiKey };
    case 'deepseek':
      return { DEEPSEEK_API_KEY: model.apiKey };
    default:
      return {};
  }
}

componentRegistry.register(definition);
